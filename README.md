# learning

A running log of things I'm learning to build strong core software engineering skills while also expanding my knowledge of [adjacent](http://www.effectiveengineer.com/blog/master-adjacent-disciplines) technologies [everyday](https://jamesclear.com/continuous-improvement).

**Updated**: Once a month | **Current** **Focus**: Generative AI

## Generic Skills

> Generic transferable skills independent of a stack

### System Design

|Format|Resource|Progress|
|---|---|---|
|Book|[Designing Machine Learning Systems](https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/)|✅|
|Udacity|[A/B Testing](https://www.udacity.com/course/ab-testing--ud257)|⬜|
||[Authentication & Authorization: OAuth](https://www.udacity.com/course/authentication-authorization-oauth--ud330)|✅|
||[Client-Server Communication](https://www.udacity.com/course/client-server-communication--ud897)|⬜|
||[Designing RESTful APIs](https://www.udacity.com/course/designing-restful-apis--ud388)|✅|
||[HTTP & Web Servers](https://www.udacity.com/course/http-web-servers--ud303)|✅|
||[Networking for Web Developers](https://www.udacity.com/course/networking-for-web-developers--ud256)|✅|
|Udemy|[AWS Certified Developer - Associate 2018](https://www.udemy.com/aws-certified-developer-associate/)|✅|
|Datacamp|[A/B Testing in Python](https://www.datacamp.com/courses/ab-testing-in-python)|⬜|
||[Customer Analytics & A/B Testing in Python](https://www.datacamp.com/courses/customer-analytics-ab-testing-in-python)|✅|
||[Machine Learning Monitoring Concepts](https://www.datacamp.com/courses/machine-learning-monitoring-concepts)|✅|
||[MLOps Concepts](https://www.datacamp.com/courses/mlops-concepts)|✅|
|Neetcode|[System Design for Beginners](https://neetcode.io/courses/system-design-for-beginners/0)|✅|
||[System Design Interview](https://neetcode.io/courses/system-design-interview)|✅|


### Maths
	
|Format|Resource|Progress|
|---|---|---|
|Datacamp|[Foundations of Probability in Python](https://www.datacamp.com/courses/foundations-of-probability-in-python)|✅|
||[Introduction to Statistics](https://www.datacamp.com/courses/introduction-to-statistics)|✅|
||[Introduction to Statistics in Python](https://www.datacamp.com/courses/introduction-to-statistics-in-python)|✅|
||[Hypothesis Testing in Python](https://www.datacamp.com/courses/hypothesis-testing-in-python)|✅|
||[Statistical Thinking in Python (Part 1)](https://www.datacamp.com/courses/statistical-thinking-in-python-part-1)|✅|
||[Statistical Thinking in Python (Part 2)](https://www.datacamp.com/courses/statistical-thinking-in-python-part-2)|✅|
||[Experimental Design in Python](https://datacamp.com/courses/experimental-design-in-python)|✅|
||[Practicing Statistics Interview Questions in Python](https://www.datacamp.com/courses/practicing-statistics-interview-questions-in-python)|⬜|
|edX|[Essential Statistics for Data Analysis using Excel](https://www.edx.org/course/essential-statistics-data-analysis-using-microsoft-dat222x-1)|✅|
|MIT|[MIT 18.06 Linear Algebra, Spring 2005](https://www.youtube.com/playlist?list=PLE7DDD91010BC51F8)|✅|
|Udacity|[Intro to Inferential Statistics](https://www.udacity.com/course/intro-to-inferential-statistics--ud201)|✅|
||[Eigenvectors and Eigenvalues](https://www.udacity.com/course/eigenvectors-and-eigenvalues--ud104)|✅|
||[Linear Algebra Refresher](https://www.udacity.com/course/linear-algebra-refresher-course--ud953)|⬜|
|Youtube|[Essence of linear algebra](https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab)|⬜|

### Data Structures and Algorithms

|Format|Resource|Progress|
|---|---|---|
|Book|[Grokking Algorithms](https://www.manning.com/books/grokking-algorithms)|✅|
|Udacity|[Intro to Data Structures and Algorithms](https://www.udacity.com/course/technical-interview--ud513)|✅|
|Neetcode|[Algorithms and Data Structures for Beginners](https://neetcode.io/courses/dsa-for-beginners/0)|✅|
||[Advanced Algorithms](https://neetcode.io/courses/advanced-algorithms/0)|`1/7`|
|Youtube|[Sliding Window Technique - Algorithmic Mental Models](https://www.youtube.com/watch?v=MK-NZ4hN7rs) `36:44`|✅|

### Data Modeling

|Format|Resource|Progress|
|---|---|---|
|Udacity|[Intro to relational database](https://www.udacity.com/course/intro-to-relational-databases--ud197)|✅|
||[SQL for Data Analysis](https://www.udacity.com/course/sql-for-data-analysis--ud198)|⬜|
||[Database Systems Concepts & Design](https://www.udacity.com/course/database-systems-concepts-and-design--ud150)|⬜|
|Datacamp|[Database Design](https://www.datacamp.com/courses/database-design)|✅|
||[Introduction to Databases in Python](https://www.datacamp.com/courses/introduction-to-relational-databases-in-python)|⬜|
||[Intro to SQL for Data Science](https://www.datacamp.com/courses/intro-to-sql-for-data-science)|✅|
||[Intermediate SQL](https://www.datacamp.com/courses/intermediate-sql)|✅|
||[Joining Data in SQL](https://www.datacamp.com/courses/joining-data-in-sql)|✅|
||[Data Manipulation in SQL](https://app.datacamp.com/learn/courses/data-manipulation-in-sql)|⬜|
||[Exploratory Data Analysis in SQL](https://www.datacamp.com/courses/sql-for-exploratory-data-analysis)|⬜|
||[Applying SQL to Real-World Problems](https://www.datacamp.com/courses/applying-sql-to-real-world-problems)|⬜|
||[Analyzing Business Data in SQL](https://www.datacamp.com/courses/analyzing-business-data-in-sql)|⬜|
||[Reporting in SQL](https://www.datacamp.com/courses/reporting-in-sql)|⬜|
||[Data-Driven Decision Making in SQL](https://www.datacamp.com/courses/data-driven-decision-making-with-sql)|⬜|
||[NoSQL Concepts](https://www.datacamp.com/courses/nosql-concepts)|✅|
||[Introduction to MongoDB in Python](https://www.datacamp.com/courses/introduction-to-using-mongodb-for-data-science-with-python)|⬜|

### UI/UX

|Format|Resource|Progress|
|---|---|---|
|Book|[Refactoring UI](https://refactoringui.com/book/)|⬜|
|Pluralsight|[UX Fundamentals](https://www.pluralsight.com/courses/ux-fundamentals-2426)|✅|
|Course|[How to Visualize Value](https://visualizevalue.com/products/how-to-visualize-value)|✅|
||[Series: K-12 Figma Design Basics](https://www.figma.com/resource-library/k-12-design-basics/)|✅|
|Youtube|[How to Make Your Website Not Ugly: Basic UX for Programmers](https://www.youtube.com/watch?v=Jf0cjocP8Wk) `48m`|⬜|
|Article|[Create an illustration in Figma design](https://help.figma.com/hc/en-us/articles/13543867954711-Create-an-illustration-in-Figma-design)|✅|


### Linux & Command Line

|Format|Resource|Progress|
|---|---|---|
|Udacity|[Linux Command Line Basics](https://www.udacity.com/course/linux-command-line-basics--ud595)|✅|
||[Shell Workshop](https://www.udacity.com/course/shell-workshop--ud206)|✅|
||[Configuring Linux Web Servers](https://www.udacity.com/course/configuring-linux-web-servers--ud299)|✅|
|Datacamp|[Introduction to Shell for Data Science](https://www.datacamp.com/courses/introduction-to-shell-for-data-science)|✅|
||[Introduction to Bash Scripting](https://www.datacamp.com/courses/introduction-to-bash-scripting)|✅|
||[Data Processing in Shell](https://www.datacamp.com/courses/data-processing-in-shell)|✅|
|MIT|[The Missing Semester](https://www.youtube.com/playlist?list=PLyzOVJj3bHQuloKGG59rS43e29ro7I57J)|✅|
|Article|[A guide to manage your environment variables in a better way using direnv](https://shivamarora.medium.com/a-guide-to-manage-your-environment-variables-in-a-better-way-using-direnv-2c1cd475c8e)|✅|

### Version Control

|Format|Resource|Progress|
|---|---|---|
|Udacity|[Version Control with Git](https://www.udacity.com/course/version-control-with-git--ud123)|✅|
||[GitHub & Collaboration](https://www.udacity.com/course/github-collaboration--ud456)|✅|
||[How to Use Git and GitHub](https://www.udacity.com/course/how-to-use-git-and-github--ud775)|✅|
|Datacamp|[Introduction to Git for Data Science](https://www.datacamp.com/courses/introduction-to-git-for-data-science)|✅|
||[Advanced Git](https://www.datacamp.com/courses/advanced-git)|✅|
|Youtube|[How to Use Git Worktree \| Checkout Multiple Git Branches at Once](https://youtu.be/s4BTvj1ZVLM)|✅|

### Testing & Profiling

|Format|Resource|Progress|
|---|---|---|
|Datacamp|[Unit Testing for Data Science in Python](https://www.datacamp.com/courses/unit-testing-for-data-science-in-python)|✅|
|Article|[Introduction to Memory Profiling in Python](https://www.datacamp.com/tutorial/memory-profiling-python)|✅|
||[Profiling Python code with memory_profiler](https://www.wrighters.io/profiling-python-code-with-memory_profiler/)|✅|
||[How to Use "memory_profiler" to Profile Memory Usage by Python Code?](https://coderzcolumn.com/tutorials/python/how-to-profile-memory-usage-in-python-using-memory-profiler)|✅|
||[Concurrency For Starlette Apps (e.g FastAPI / FastHTML)](https://hamel.dev/notes/fasthtml/concurrency.html#fnref1)|✅|
|Youtube|[Debug Python inside Docker using debugpy and VSCode](https://www.youtube.com/watch?v=ywfsLKRLmf4)|✅|

### Programming

|Format|Resource|Progress|
|---|---|---|
|Book|[Python 201](https://leanpub.com/python201)|⬜|
||[Writing Idiomatic Python 3](https://www.amazon.com/Writing-Idiomatic-Python-Jeff-Knupp-ebook/dp/B00B5VXMRG)|⬜|
|Datacamp|[Writing Efficient Python Code](https://www.datacamp.com/courses/writing-efficient-python-code)|✅|
||[Writing Functions in Python](https://www.datacamp.com/courses/writing-functions-in-python)|✅|
||[Object-Oriented Programming in Python](https://www.datacamp.com/courses/object-oriented-programming-in-python)|✅|
||[Intermediate Object-Oriented Programming in Python](https://www.datacamp.com/courses/intermediate-object-oriented-programming-in-python)|✅|
||[Importing Data in Python (Part 1)](https://www.datacamp.com/courses/importing-data-in-python-part-1)|✅|
||[Importing Data in Python (Part 2)](https://www.datacamp.com/courses/importing-data-in-python-part-2)|✅|
||[Intermediate Python for Data Science](https://www.datacamp.com/courses/intermediate-python-for-data-science)|✅|
||[Python Data Science Toolbox (Part 1)](https://www.datacamp.com/courses/python-data-science-toolbox-part-1)|✅|
||[Python Data Science Toolbox (Part 2)](https://www.datacamp.com/courses/python-data-science-toolbox-part-2)|✅|
||[Developing Python Packages](https://www.datacamp.com/courses/developing-python-packages)|✅|
||[Conda Essentials](https://www.datacamp.com/courses/conda-essentials)|✅|
||[Working with Dates and Times in Python](https://www.datacamp.com/courses/working-with-dates-and-times-in-python)|✅|
||[Command Line Automation in Python](https://www.datacamp.com/courses/command-line-automation-in-python)|⬜|
|Youtube|[Tutorial: Sebastian Witowski - Modern Python Developer's Toolkit](https://www.youtube.com/watch?v=WkUBx3g2QfQ&feature=youtu.be)|✅|
|Article|[Python's many command-line utilities](https://www.pythonmorsels.com/cli-tools/)|⬜|
||[A Programmer’s Introduction to Unicode](https://www.reedbeta.com/blog/programmers-intro-to-unicode/)|⬜|
||[Exposing string types to maximize user happiness](https://stephantul.github.io/python/typing/2025/03/07/externalized-types/)|✅|

### Development Environment

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[Build Apps with Windsurf’s AI Coding Agents](https://www.deeplearning.ai/short-courses/build-apps-with-windsurfs-ai-coding-agents/) `1h10m`|✅|
|Pluralsight|[Using The Chrome Developer Tools](https://www.pluralsight.com/courses/chrome-developer-tools)|✅|
|Youtube|[Prompt Driven Development Series](https://www.youtube.com/playlist?list=PLj6YeMhvp2S6SxK3u_W5oN5neaZUpYK3O) `9/9`|✅|
|Docs|[VSCode Docs: Python Interactive window](https://code.visualstudio.com/docs/python/jupyter-support-py)|⬜|


## Specialized Skills
<hr>

### Traditional Machine Learning

|Format|Resource|Progress|
|---|---|---|
|Book|[Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 2nd Edition](https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/)|⬜|
||[A Machine Learning Primer](https://www.confetti.ai/assets/ml-primer/ml_primer.pdf)|✅|
||[Grokking Machine Learning](https://www.manning.com/books/grokking-machine-learning)|✅|
||[The StatQuest Illustrated Guide To Machine Learning](https://www.amazon.com/StatQuest-Illustrated-Guide-Machine-Learning/dp/B0BLM4TLPY)|✅|
|Datacamp|[Ensemble Methods in Python](https://www.datacamp.com/courses/ensemble-methods-in-python)|✅|
||[Extreme Gradient Boosting with XGBoost](https://www.datacamp.com/courses/extreme-gradient-boosting-with-xgboost)|⬜|
||[Clustering Methods with SciPy](https://www.datacamp.com/courses/clustering-methods-with-scipy)|✅|
||[Unsupervised Learning in Python](https://www.datacamp.com/courses/unsupervised-learning-in-python)|✅|
||[Supervised Learning with scikit-learn](https://www.datacamp.com/courses/supervised-learning-with-scikit-learn)|✅|
||[Machine Learning with Tree-Based Models in Python](https://www.datacamp.com/courses/machine-learning-with-tree-based-models-in-python)|✅|
||[Linear Classifiers in Python](https://www.datacamp.com/courses/linear-classifiers-in-python)|✅|
||[Model Validation in Python](https://www.datacamp.com/courses/model-validation-in-python)|✅|
||[Hyperparameter Tuning in Python](https://www.datacamp.com/courses/hyperparameter-tuning-in-python)|✅|
||[HR Analytics in Python: Predicting Employee Churn](https://www.datacamp.com/courses/hr-analytics-in-python-predicting-employee-churn)|✅|
||[Predicting Customer Churn in Python](https://www.datacamp.com/courses/predicting-customer-churn-in-python)|✅|
||[Dimensionality Reduction in Python](https://www.datacamp.com/courses/dimensionality-reduction-in-python)|✅|
||[Preprocessing for Machine Learning in Python](https://www.datacamp.com/courses/preprocessing-for-machine-learning-in-python)|✅|
||[Data Types for Data Science](https://www.datacamp.com/courses/data-types-for-data-science)|✅|
||[Cleaning Data in Python](https://www.datacamp.com/courses/cleaning-data-in-python)|✅|
||[Feature Engineering for Machine Learning in Python](https://www.datacamp.com/courses/feature-engineering-for-machine-learning-in-python)|✅|
||[Predicting CTR with Machine Learning in Python](https://www.datacamp.com/courses/predicting-ctr-with-machine-learning-in-python)|✅|
||[Intro to Financial Concepts using Python](https://www.datacamp.com/courses/intro-to-financial-concepts-using-python)|✅|
||[Fraud Detection in Python](https://www.datacamp.com/courses/fraud-detection-in-python)|✅|
||[Segmentation and Clustering](https://www.udacity.com/course/segmentation-and-clustering--ud981)|✅|
||[Intro to Python for Data Science](https://www.datacamp.com/courses/intro-to-python-for-data-science)|✅|
|edX|[Implementing Predictive Analytics with Spark in Azure HDInsight](https://www.edx.org/course/implementing-predictive-analytics-spark-microsoft-dat202-3x-2)|✅|
|Article|[The wrong batch size is all it takes](https://articles.bnomial.com/the-wrong-batch-size-is-all-it-takes)|✅|
||[A Gentle Introduction to Expectation-Maximization (EM Algorithm)](https://machinelearningmastery.com/expectation-maximization-em-algorithm/)|✅|
||[How to Use Out-of-Fold Predictions in Machine Learning](https://machinelearningmastery.com/out-of-fold-predictions-in-machine-learning/)|✅|
||[Stacking and Blending — An Intuitive Explanation](https://medium.com/@stevenyu530_73989/stacking-and-blending-intuitive-explanation-of-advanced-ensemble-methods-46b295da413c)|✅|


### Deep Learning

|Format|Resource|Progress|
|---|---|---|
|Book|[Make Your Own Neural Network](https://www.amazon.com/Make-Your-Own-Neural-Network/dp/1530826608)|✅|
|Fast.ai|[Practical Deep Learning for Coder (Part 1)](https://course.fast.ai/)|✅|
||[Practical Deep Learning for Coder (Part 2)](https://course.fast.ai/Lessons/part2.html) `9, 13,14,17,18(48:10),19`|⬜|
|Datacamp|[Convolutional Neural Networks for Image Processing](https://www.datacamp.com/courses/convolutional-neural-networks-for-image-processing)|✅|
|Karpathy|[Neural Networks: Zero to Hero](https://github.com/karpathy/nn-zero-to-hero/)|✅|
|Article|[An overview of gradient descent optimization algorithms](https://www.ruder.io/optimizing-gradient-descent)|✅|
||[Things that confused me about cross-entropy](https://chris-said.io/2020/12/26/two-things-that-confused-me-about-cross-entropy/)|✅|
||[Why is the ReLU function not differentiable at x=0?](https://sebastianraschka.com/faq/docs/relu-derivative.html)|✅|
||[Are CNNs invariant to translation, rotation, and scaling?](https://pyimagesearch.com/2021/05/14/are-cnns-invariant-to-translation-rotation-and-scaling/)|✅|
||[How to Control the Stability of Training Neural Networks With the Batch Size](https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/)|✅|
||[A Visual Guide to Learning Rate Schedulers in PyTorch](https://www.leoniemonigatti.com/blog/pytorch-learning-rate-schedulers.html)|✅|


### Natural Language Processing


|Format|Resource|Progress|
|---|---|---|
|Book|[Book: Natural Language Processing with Transformers](https://transformersbook.com/)|✅|
|Stanford|[CS224U: Natural Language Understanding \| Spring 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rObpMCir6rNNUlFAn56Js20) `15/15 lectures`|✅|
||[CS224N: NLP with Deep Learning \| Winter 2019](https://www.youtube.com/playlist?list=PLoROMvodv4rOhcuXMZkNm7j3fVwBBY42z) `22/22 lectures`|✅|
|CMU|[Low-resource NLP Bootcamp 2020](https://www.youtube.com/playlist?list=PL8PYTP1V4I8A1CpCzURXAUa6H4HO7PF2c) `8/8 lectures`|✅|
||[Multilingual NLP 2020](http://demo.clab.cs.cmu.edu/11737fa20/)|✅|
|Datacamp|[Feature Engineering for NLP in Python](https://www.datacamp.com/courses/feature-engineering-for-nlp-in-python)|✅|
||[Natural Language Processing Fundamentals in Python](https://www.datacamp.com/courses/natural-language-processing-fundamentals-in-python)|✅|
||[Regular Expressions in Python](https://www.datacamp.com/courses/regular-expressions-in-python)|✅|
||[RNN for Language Modeling](https://www.datacamp.com/courses/recurrent-neural-networks-for-language-modeling-in-python)|✅|
||[Natural Language Generation in Python](https://www.datacamp.com/courses/natural-language-generation-in-python)|✅|
||[Building Chatbots in Python](https://www.datacamp.com/courses/building-chatbots-in-python)|✅|
||[Sentiment Analysis in Python](https://www.datacamp.com/courses/sentiment-analysis-in-python)|✅|
||[Machine Translation in Python](https://www.datacamp.com/courses/machine-translation-in-python)|✅|
|Article|[The Unreasonable Effectiveness of Collocations](https://opensourceconnections.com/blog/2019/05/16/unreasonable-effectiveness-of-collocations/)|⬜|
||[FuzzyWuzzy: Fuzzy String Matching in Python](https://chairnerd.seatgeek.com/fuzzywuzzy-fuzzy-string-matching-in-python/#)|✅|
||[Transformers: Origins](https://mark-riedl.medium.com/transformers-origins-1db4bdfcb3d1)|⬜|
||[Understanding the Difference Between Embedding Layers and Linear Layers](https://github.com/rasbt/LLMs-from-scratch/blob/main/ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb)|✅|

### Generative AI
<hr>

#### LLM Theory

|Format|Resource|Progress|
|---|---|---|
|Book|[Hands-On Large Language Models: Language Understanding and Generation](https://www.amazon.com/Hands-Large-Language-Models-Understanding/dp/1098150961)|✅|
||[Large Language Models: A Deep Dive: Bridging Theory and Practice](https://www.amazon.com/Large-Language-Models-Bridging-Practice/dp/3031656466)|⬜|
||[Build a Large Language Model (From Scratch)](https://www.manning.com/books/build-a-large-language-model-from-scratch)|`246/581`|
||[The Hundred-Page Language Models Book](https://thelmbook.com/)|✅|
||[Super Study Guide: Transformers & Large Language Models](https://www.amazon.com/Super-Study-Guide-Transformers-Language/dp/B0DC4NYLTN)|✅|
||[The Smol Training Playbook: The Secrets to Building World-Class LLMs](https://huggingface.co/spaces/HuggingFaceTB/smol-training-playbook#training-compass-why--what--how)|⬜|
|DeepLearning.AI|[Pretraining LLMs](https://www.deeplearning.ai/short-courses/pretraining-llms)|✅|
||[Reinforcement Learning from Human Feedback](https://www.deeplearning.ai/short-courses/reinforcement-learning-from-human-feedback)|✅|
||[How Transformer LLMs Work](https://www.deeplearning.ai/short-courses/how-transformer-llms-work/)|✅|
|Karpathy|[Intro to Large Language Models](https://www.youtube.com/watch?v=zjkBMFhNj_g) `1hr`|✅|
||[Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE) `2hr13m`|✅|
||[Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU) `4hr1m`|✅|
||[Deep Dive into LLMs like ChatGPT](https://www.youtube.com/watch?v=7xTGNNLPyMI) `3h31m`|✅|
|Youtube|[5 Years of GPTs with Finbarr Timbers](https://www.youtube.com/watch?v=YA0pzBYAV2Q&list=PLKlhhkvvU8-YxMP9hjEYJTJDCaGszrJIh&index=8&t=43s) `55m`|✅|
||[A Hackers' Guide to Language Models](https://www.youtube.com/watch?v=jkrNMKz9pWU) `1hr30m`|✅|
||[Stanford CS229 I Machine Learning I Building Large Language Models (LLMs)](https://www.youtube.com/watch?v=9vM4p9NN0Ts) `1h44m`|✅|
||[LLaMA explained: KV-Cache, Rotary Positional Embedding, RMS Norm, Grouped Query Attention, SwiGLU](https://www.youtube.com/watch?v=Mn_9W1nCFLo) `1h10m`|✅|
||[CMU Advanced NLP Fall 2024 (14): Ensembling and Mixture of Experts](https://www.youtube.com/watch?v=E4Rg4qTw4xw&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=15)|✅|
||[A little guide to building Large Language Models in 2024](https://www.youtube.com/watch?v=2-SPH9hIKT8) `1h15m`|✅|
||[How I use LLMs](https://youtu.be/EWvNQjAaOHw) `2h7m`|✅|
||[Simple Diffusion Language Models](https://youtu.be/WjAUX23vgfg)|✅|
||[Zed Inferred: Diffusion Language Models](https://youtu.be/oot4O9wMohw?list=LL)|✅|
|Article|[You could have designed state of the art Positional Encoding](https://fleetwood.dev/posts/you-could-have-designed-SOTA-positional-encoding)|✅|
||[From Digits to Decisions: How Tokenization Impacts Arithmetic in LLMs](https://huggingface.co/spaces/huggingface/number-tokenization-blog)|✅|
||[SolidGoldMagikarp (plus, prompt generation)](https://www.lesswrong.com/posts/aPeJE8bSo6rAFoLqg/solidgoldmagikarp-plus-prompt-generation)|✅|
||[Sampling for Text Generation](https://huyenchip.com/2024/01/16/sampling.html)|✅|
||[First Token Cutoff LLM sampling](https://antirez.com/news/142)|✅|
||[The Big LLM Architecture Comparison](https://magazine.sebastianraschka.com/p/the-big-llm-architecture-comparison)|✅|
||[From GPT-2 to gpt-oss: Analyzing the Architectural Advances](https://sebastianraschka.com/blog/2025/from-gpt-2-to-gpt-oss.html)|✅|
||[A Visual Guide to Mamba and State Space Models](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mamba-and-state)|⬜|
||[Patterns and Messages - Part 1 - The Missing Subscript](https://mccormickml.com/2025/02/18/patterns-and-messages-part-1-wo-i/)|✅|
||[How text diffusion works](https://pierce.dev/notes/how-text-diffusion-works/)|✅|
||[The Illustrated Evo 2](https://research.nvidia.com/labs/dbr/blog/illustrated-evo2/)|⬜|
||[Interpreting the Prediction of BERT Model for Text Classification](https://towardsdatascience.com/interpreting-the-prediction-of-bert-model-for-text-classification-5ab09f8ef074/)|✅|
||[2025: The year in LLMs](https://simonwillison.net/2025/Dec/31/the-year-in-llms/)|✅|
||[Things we learned about LLMs in 2024](https://simonwillison.net/2024/Dec/31/llms-in-2024/)|⬜|
||[Synthetic pretraining](https://vintagedata.org/blog/posts/synthetic-pretraining)|⬜|

#### Post-training (RLHF / RLVR)

|Format|Resource|Progress|
|---|---|---|
|Book|[A Little Bit of Reinforcement Learning from Human Feedback](https://rlhfbook.com/)|✅|
|DeepLearning.AI|[Post-training of LLMs](https://www.deeplearning.ai/short-courses/post-training-of-llms/)|✅|
|Youtube|[How DeepSeek Changes the LLM Story](https://www.youtube.com/watch?v=0eMzc-WnBfQ)|✅|
||[Speculations on Test-Time Scaling (o1)](https://www.youtube.com/watch?v=6PEJ96k1kiw) `47m`|✅|
||[DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://youtu.be/XMnxKGVnEUc) `1h19m`|✅|
||[MIT EI seminar, Hyung Won Chung from OpenAI. "Don't teach. Incentivize."](https://www.youtube.com/watch?v=kYWUEV_e2ss) `35m`|✅|
||[Group Relative Policy Optimization (GRPO) - Formula and Code](https://www.youtube.com/watch?v=Yi1UCrAsf4o) `24m`|✅|
||[How to approach post-training for AI applications](https://www.youtube.com/watch?v=grpc-Wyy-Zg) `22m`|✅|
|Article|[Scaling test-time compute - a Hugging Face Space by HuggingFaceH4](https://huggingface.co/spaces/HuggingFaceH4/blogpost-scaling-test-time-compute)|✅|
||[DeepSeek R1's recipe to replicate o1 and the future of reasoning LMs](https://www.interconnects.ai/p/deepseek-r1-recipe-for-o1)|✅|
||[The Illustrated DeepSeek-R1](https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1)|✅|
||[A Visual Guide to Reasoning LLMs](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-reasoning-llms)|✅|
||[GRPO in DeepSeek-R1](https://hlfshell.ai/posts/grpo/)|✅|


#### Multi-modality (Vision)

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[How Diffusion Models Work](https://www.deeplearning.ai/short-courses/how-diffusion-models-work/)|✅|
||[Prompt Engineering for Vision Models](https://www.deeplearning.ai/short-courses/prompt-engineering-for-vision-models/)|⬜|
||[Building Multimodal Search and RAG](https://www.deeplearning.ai/short-courses/building-multimodal-search-and-rag/)|✅|
|Youtube|[Lesson 9A 2022 - Stable Diffusion deep dive](https://youtu.be/0_BBRNYInx8)|✅|
||[AI Visions Live \| Merve Noyan \| Open-source Multimodality](https://www.youtube.com/watch?v=_TlhKHTgWjY) `54m`|✅|
||[Sander Dieleman - Generative modelling through iterative refinement](https://www.youtube.com/watch?v=9BHQvQlsVdE)|✅|
|Article|[Pinecone: Embedding Methods for Image Search](https://www.pinecone.io/learn/series/image-search/)|0/8|
||[Understanding Multimodal LLMs](https://magazine.sebastianraschka.com/p/understanding-multimodal-llms)|✅|
||[Computer-Using Agent](https://openai.com/index/computer-using-agent/)|✅|
||[Flow Matching in 5 Minutes](https://nrehiew.github.io/blog/flow_matching/)|✅|
||[Understanding Patch Embeddings for Vision Transformers (ViT)](https://medium.com/@frederik.vl/understanding-vision-transformers-vit-70ca8d817ff3)|✅|
||[Diffusion models are autoencoders](https://sander.ai/2022/01/31/diffusion.html)|✅|
||[Diffusion Language Models](https://sander.ai/2023/01/09/diffusion-language.html)|✅|
||[Guidance: a cheat code for diffusion models](https://sander.ai/2022/05/26/guidance.html)|✅|
||[Perspectives on diffusion](https://sander.ai/2023/07/20/perspectives.html)|✅|
||[The geometry of diffusion guidance](https://sander.ai/2023/08/28/geometry.html)|✅|
||[Diffusion is spectral autoregression](https://sander.ai/2024/09/02/spectral-autoregression.html)|✅|
||[Generative modelling in latent space](https://sander.ai/2025/04/15/latents.html)|✅|

#### Multi-modality (Audio)

|Format|Resource|Progress|
|---|---|---|
|Article|[Speech AI models: an introduction](https://thomwolf.io/blog/speech-ai.html)|⬜|
||[Voice AI & Voice Agents - An Illustrated Primer](https://voiceaiandvoiceagents.com/)|⬜|
||[Neural audio codecs: how to get audio into LLMs](https://kyutai.org/next/codec-explainer)|⬜|

#### Quantization

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[Quantization Fundamentals with Hugging Face](https://www.deeplearning.ai/short-courses/quantization-fundamentals-with-hugging-face/)|✅|
||[Quantization in Depth](https://www.deeplearning.ai/short-courses/quantization-in-depth/)|⬜|
||[Introduction to On-Device AI](https://www.deeplearning.ai/short-courses/introduction-to-on-device-ai/)|⬜|
|Youtube|[CMU Advanced NLP Fall 2024 (11): Distillation, Quantization, and Pruning](https://www.youtube.com/watch?v=DvVGkj4zhVU&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=5)|⬜|
|Article|[A Visual Guide to Quantization](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-quantization)|⬜|
||[QLoRA and 4-bit Quantization](https://mccormickml.com/2024/09/14/qlora-and-4bit-quantization/)|⬜|
||[Understanding AI/LLM Quantisation Through Interactive Visualisations](https://smcleod.net/2024/07/understanding-ai/llm-quantisation-through-interactive-visualisations/)|⬜|
||[LLM.int8() and Emergent Features](https://timdettmers.com/2022/08/17/llm-int8-and-emergent-features/)|⬜|

#### Distributed Training

|Format|Resource|Progress|
|---|---|---|
|Youtube|[Slaying OOMs with PyTorch FSDP and torchao](https://youtu.be/UvRl4ansfCg) `49m`|✅|
||[Distributed Training with PyTorch: complete tutorial with cloud infrastructure and code](https://youtu.be/toUSzwR0EV8) `1h12m`|✅|
||[How DDP works \|\| Distributed Data Parallel ](https://youtu.be/bwNtfxEDjGA)|✅|
||[FSDP Explained](https://youtu.be/6pVn6khIgiI)|✅|
||[Lecture 48: The Ultra Scale Playbook](https://youtu.be/1E8GDR8QXKw) `3h3m`|`44:24`|
||[Invited Talk: PyTorch Distributed (DDP, RPC) - By Facebook Research Scientist Shen Li](https://youtu.be/3XUG7cjte2U)|✅|
||[Unit 9 \| Techniques for Speeding Up Model Training](https://www.youtube.com/playlist?list=PLaMu-SDt_RB403GN5DU7NYVoVmO5Vsgkh)|✅|
|Article|[A Short Guide to PyTorch DDP](https://blog.hpc.qmul.ac.uk/pytorch-ddp/)|✅|
||[Scaling Deep Learning with PyTorch: Multi-Node and Multi-GPU Training Explained (with Code)](https://medium.com/@ashraf.kasem.94.0/scaling-deep-learning-with-pytorch-multi-node-and-multi-gpu-training-explained-with-code-ece8f03ea59b)|✅|
||[Accelerating PyTorch Model Training](https://magazine.sebastianraschka.com/p/accelerating-pytorch-model-training)|✅|
||[Meet Horovod: Uber’s Open Source Distributed Deep Learning Framework for TensorFlow](https://www.uber.com/blog/horovod/)|✅|
||[Distributed data parallel training in Pytorch](https://yangkky.github.io/2019/07/08/distributed-pytorch-tutorial.html)|✅|
||[Training on Multiple GPUs](https://d2l.ai/chapter_computational-performance/multiple-gpus.html)|✅|


#### Parallel Computing

|Format|Resource|Progress|
|---|---|---|
|Book|[Programming Massively Parallel Processors: A Hands-on Approach](https://www.amazon.com/Programming-Massively-Parallel-Processors-Hands/dp/0124159923)|`Ch. 2`|
||[The Algebra of Speed](https://ttsugriy.github.io/performance-book/)|⬜|
|Udacity|[Intro to Parallel Programming](https://www.youtube.com/playlist?list=PLAwxTw4SYaPnFKojVQrmyOGFCqHTxfdv2) `458 video`|`299/458`|
|Youtube|[GPU Puzzles: Let's Play](https://youtu.be/K4T-YwsOxrM)|⬜|

#### Inference Optimization

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[Efficiently Serving LLMs](https://www.deeplearning.ai/short-courses/efficiently-serving-llms/)|✅|
|Youtube|[Deploying Fine-Tuned Models](https://youtu.be/GzEcyBykkdo) `2h28m`|✅|
|Article|[How to make LLMs go fast](https://vgel.me/posts/faster-inference/)|✅|
||[In the Fast Lane! Speculative Decoding - 10x Larger Model, No Extra Cost](https://docs.titanml.co/blog/speculative-decoding-unleashed/)|⬜|
||[Accelerating Generative AI with PyTorch II: GPT, Fast](https://pytorch.org/blog/accelerating-generative-ai-2/)|⬜|
||[Harmonizing Multi-GPUs: Efficient Scaling of LLM Inference](https://docs.titanml.co/blog/multi-gpu/)|⬜|
||[Multi-Query Attention is All You Need](https://fireworks.ai/blog/multi-query-attention-is-all-you-need)|⬜|
||[Transformers Inference Optimization Toolset](https://astralord.github.io/posts/transformer-inference-optimization-toolset/)|⬜|
||[LLM Inference Series: 3. KV caching explained](https://medium.com/@plienhar/llm-inference-series-3-kv-caching-unveiled-048152e461c8)|⬜|
||[LLM Inference Series: 4. KV caching, a deeper look](https://medium.com/@plienhar/llm-inference-series-4-kv-caching-a-deeper-look-4ba9a77746c8)|⬜|
||[LLM Inference Series: 5. Dissecting model performance](https://medium.com/@plienhar/llm-inference-series-5-dissecting-model-performance-6144aa93168f)|⬜|
||[Transformer Inference Arithmetic](https://kipp.ly/transformer-inference-arithmetic/)|⬜|
||[Optimizing AI Inference at Character.AI](https://research.character.ai/optimizing-inference/)|⬜|
||[Optimizing AI Inference at Character.AI (Part Deux)](https://research.character.ai/optimizing-ai-inference-at-character-ai-part-deux/)|⬜|
||[llama.cpp guide - Running LLMs locally, on any hardware, from scratch](https://blog.steelph0enix.dev/posts/llama-cpp-guide/)|✅|
||[Domain specific architectures for AI inference](https://fleetwood.dev/posts/domain-specific-architectures)|⬜|
||[SBTB 2023: Charles Frye, Parallel Processors: Past & Future Connections Between LLMs and OS Kernels](https://www.youtube.com/watch?v=VxFtHqlMv8c)|✅|
||[Compiling ML models to C for fun](https://bernsteinbear.com/blog/compiling-ml-models/)|⬜|
||[How to Optimize a CUDA Matmul Kernel for cuBLAS-like Performance: a Worklog](https://siboehm.com/articles/22/CUDA-MMM)|⬜|
||[Inside vLLM: Anatomy of a High-Throughput LLM Inference System](https://www.aleksagordic.com/blog/vllm)|⬜|
||[Understanding LLM Inference Engines: Inside Nano-vLLM (Part 1)](https://neutree.ai/blog/nano-vllm-part-1)|⬜|
||[Understanding LLM Inference Engines: Inside Nano-vLLM (Part 2)](https://neutree.ai/blog/nano-vllm-part-2)|⬜|
||[Defeating Nondeterminism in LLM Inference](https://thinkingmachines.ai/blog/defeating-nondeterminism-in-llm-inference/)|⬜|
||[Prompt caching: 10x cheaper LLM tokens, but how?](https://ngrok.com/blog/prompt-caching/)|⬜|
||[Attention Mechanism: From Math to GPU](https://isztld.com/posts/attention-mechanism.html)|⬜|


### Finetuning and Distillation

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[Finetuning Large Language Models](https://www.deeplearning.ai/short-courses/finetuning-large-language-models/)|✅|
|OpenAI|[GPT-4o mini Fine-Tuning Build Hour](https://vimeo.com/showcase/11333741/video/995989828)|✅|
||[Distillation Build Hour](https://vimeo.com/showcase/11333741/video/1029408095)|✅|
|Youtube|[Fine-Tuning with Axolotl](https://youtu.be/mmsa4wDsiy0?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC) `2h10m`|✅|
||[Creating, Curating, and Cleaning Data for LLMs](https://youtu.be/HEGaei7k0zE?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC) `54m`|✅|
||[Best Practices For Fine Tuning Mistral](https://youtu.be/Z_oWzTuljss?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC) `23m`|✅|
||[Fine Tuning OpenAI Models - Best Practices](https://youtu.be/Q0GSZD0Na1s?list=PLgIaq8VgndJtZ_G6gxyuhHGLUy9zXV9JC)|✅|
||[When and Why to Fine Tune an LLM](https://youtu.be/cPn0nHFsvFg) `1h56m`|✅|
||[Napkin Math For Fine Tuning Pt. 1 w/Johno Whitaker](https://youtu.be/-2ebSQROew4)|✅|
||[Napkin Math For Fine Tuning Pt. 2 w/Johno Whitaker](https://youtu.be/u2fJ6K8FjS8)|✅|
||[Fine Tuning LLMs for Function Calling w/Pawel Garback](https://youtu.be/SEZ7j31u67A) `1h32m`|✅|
||[From Prompt to Model: Fine-tuning when you've already deployed LLMs in prod w/Kyle Corbitt](https://youtu.be/4EPZZkVrXC4) `32m`|✅|
||[Why Fine Tuning is Dead w/Emmanuel Ameisen](https://youtu.be/h1c_jmk97Ss) `50m`|✅|
|Article|[Tokenization Gotchas](https://hamel.dev/notes/llm/finetuning/tokenizer_gotchas.html)|⬜|
||[Practical Tips for Finetuning LLMs Using LoRA (Low-Rank Adaptation)](https://magazine.sebastianraschka.com/p/practical-tips-for-finetuning-llms)|⬜|
||[How to Generate and Use Synthetic Data for Finetuning](https://eugeneyan.com/writing/synthetic/)|✅|


### AI Engineering
<hr>

#### LLM System Design

|Format|Resource|Progress|
|---|---|---|
|Book|[AI Engineering: Building Applications with Foundation Models](https://www.amazon.com/AI-Engineering-Building-Applications-Foundation/dp/1098166302)|✅|
||[Designing Large Language Model Applications](https://www.oreilly.com/library/view/designing-large-language/9781098150495/)|⬜|
|Course|[LLM Bootcamp - Spring 2023](https://fullstackdeeplearning.com/llm-bootcamp/spring-2023/)|✅|
|DeepLearning.AI|[Building Systems with the ChatGPT API](https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/)|⬜|
||[Building Generative AI Applications with Gradio](https://www.deeplearning.ai/short-courses/building-generative-ai-applications-with-gradio/)|✅|
||[LLMOps](https://www.deeplearning.ai/short-courses/llmops/)|⬜|
||[Serverless LLM apps with Amazon Bedrock](https://www.deeplearning.ai/short-courses/serverless-llm-apps-amazon-bedrock/)|⬜|
|Youtube|[A Survey of Techniques for Maximizing LLM Performance](https://www.youtube.com/watch?v=ahnGLM-RC1Y)|✅|
||[Building Blocks for LLM Systems & Products: Eugene Yan](https://www.youtube.com/watch?v=LzeC1AQ-U5o)|✅|
||[Building LLM Applications](https://www.youtube.com/playlist?list=PLgIaq8VgndJtrxcelEdnXbvh9fXMHeAps)|0/8|
||[Getting the Most Out of Your LLM Experiments](https://youtu.be/IfcDvtl6Z1Y) `48m`|✅|
|Article|[What We’ve Learned From A Year of Building with LLMs](https://applied-llms.org/)|✅|
||[Data Flywheels for LLM Applications](https://www.sh-reya.com/blog/ai-engineering-flywheel/)|⬜|
||[Emerging Architectures for LLM Applications](https://a16z.com/emerging-architectures-for-llm-applications/)|✅|
||[Patterns for Building LLM-based Systems & Products](https://eugeneyan.com/writing/llm-patterns/)|✅|
||[LLM From the Trenches: 10 Lessons Learned Operationalizing Models at GoDaddy](https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-3-prompts-aren-t-portable-across-models)|✅|
||[Emerging UX Patterns for Generative AI Apps & Copilots](https://www.tidepool.so/blog/emerging-ux-patterns-for-generative-ai-apps-copilots)|✅|
||[The Novice's LLM Training Guide](https://rentry.co/llm-training)|⬜|
||[Pushing ChatGPT's Structured Data Support To Its Limits](https://minimaxir.com/2023/12/chatgpt-structured-data/)|✅|
||[GPTed: using GPT-3 for semantic prose-checking](https://vgel.me/posts/gpted-launch/)|✅|
||[Don't worry about LLMs](https://vickiboykis.com/2024/05/20/dont-worry-about-llms/)|⬜|
||[Data acquisition strategies for AI-first start-ups](https://press.airstreet.com/p/data-acquisition-strategies-for-ai?utm_source=substack&utm_medium=email)|⬜|
||[All about synthetic data generation](https://blog.ragas.io/all-about-synthetic-data-generation)|✅|

#### Evals and Guardrails

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[Automated Testing for LLMOps](https://www.deeplearning.ai/short-courses/automated-testing-llmops/)|✅|
||[Red Teaming LLM Applications](https://www.deeplearning.ai/short-courses/red-teaming-llm-applications/)|✅|
||[Evaluating and Debugging Generative AI Models Using Weights and Biases](https://www.deeplearning.ai/short-courses/evaluating-debugging-generative-ai/)|⬜|
||[Quality and Safety for LLM Applications](https://www.deeplearning.ai/short-courses/quality-safety-llm-applications/)|⬜|
|Youtube|[OpenAI: Evals Build Hour](https://vimeo.com/showcase/11333741/video/1023317525)|✅|
||[Instrumenting & Evaluating LLMs](https://youtu.be/SnbGD677_u0) `2hr33m`|✅|
||[LLM Eval For Text2SQL](https://youtu.be/UGmenkjGXqM?list=PLgIaq8VgndJvt-HKMHPXehyJNNXQsAVHD) `51m`|✅|
||[A Deep Dive on LLM Evaluation](https://youtu.be/IsZVCnViwhk?list=PLgIaq8VgndJvt-HKMHPXehyJNNXQsAVHD) `49m`|✅|
|Article|[Understanding the 4 Main Approaches to LLM Evaluation (From Scratch)](https://sebastianraschka.com/blog/2025/llm-evaluation-4-approaches.html)|✅|
||[Your AI Product Needs Evals](https://hamel.dev/blog/posts/evals)|✅|
||[Task-Specific LLM Evals that Do & Don't Work](https://eugeneyan.com/writing/evals/)|✅|
||[Evaluation & Hallucination Detection for Abstractive Summaries](https://eugeneyan.com/writing/abstractive/)|✅|
||[Evaluating the Effectiveness of LLM-Evaluators (aka LLM-as-Judge)](https://eugeneyan.com/writing/llm-evaluators/)|⬜|
||[Aligning LLM as judge with human evaluators](https://blog.ragas.io/aligning-llm-as-judge-with-human-evaluators)|✅|
||[Hard-Earned Lessons from 2 Years of Improving AI Applications](https://blog.ragas.io/hard-earned-lessons-from-2-years-of-improving-ai-applications)|✅|
||[Evaluating Long-Context Question & Answer Systems](https://eugeneyan.com/writing/qa-evals/)|⬜|
||[LLM Evals FAQ](https://hamel.dev/blog/posts/evals-faq/)|✅|

#### Context Engineering

|Format|Resource|Progress|
|---|---|---|
|Book|[Prompt Engineering for LLMs](https://www.oreilly.com/library/view/prompt-engineering-for/9781098156145/)|⬜|
|Anthropic|[Anthropic Courses](https://github.com/anthropics/courses)|⬜|
||[Anthropic: The Claude in Amazon Bedrock Course](https://www.anthropic.com/aws-reinvent-2024/course)|⬜|
|DeepLearning.AI|[Reasoning with o1](https://www.deeplearning.ai/short-courses/reasoning-with-o1/)|✅|
||[ChatGPT Prompt Engineering for Developers](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)|⬜|
|Course|[LLM Engineering - Structured Outputs](https://www.wandb.courses/courses/steering-language-models)|⬜|
|Youtube|[OpenAI: Reasoning with o1 Build Hour](https://vimeo.com/showcase/11333741/video/1018737829)|✅|
||[Prompt Engineering Overview](https://www.youtube.com/watch?v=dOxUroR57xs) `1hr4m`|✅|
||[Prompt Engineering Workshop](https://youtu.be/htBTho6oEJA) `1h`|✅|
||[Context Engineering SF - August 20th, 2025](https://www.youtube.com/playlist?list=PL5q_lef6zVkb2j0SjbqFWLUdTTvkEnfaL) `4/4 videos`|✅|
|Article|[OpenAI Prompt Engineering](https://platform.openai.com/docs/guides/prompt-engineering)|⬜|
||[Prompting Fundamentals and How to Apply them Effectively](https://eugeneyan.com/writing/prompting/)|✅|
||[How I came in first on ARC-AGI-Pub using Sonnet 3.5 with Evolutionary Test-time Compute](https://params.com/@jeremy-berman/arc-agi)|✅|
||[Prompt Engineering(Liliang Weng)](https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/)|✅|
||[Prompt Engineering 201: Advanced methods and toolkits](https://amatria.in/blog/prompt201)|✅|
||[Optimizing LLMs for accuracy](https://platform.openai.com/docs/guides/optimizing-llm-accuracy)|✅|
||[Primers • Prompt Engineering](https://aman.ai/primers/ai/prompt-engineering/)|⬜|
||[Anyscale Endpoints: JSON Mode and Function calling Features](https://www.anyscale.com/blog/anyscale-endpoints-json-mode-and-function-calling-features)|⬜|
||[Guided text generation with Large Language Models](https://medium.com/productizing-language-models/guided-text-generation-with-large-language-models-d88fc3dcf4c)|⬜|
||[Effective context engineering for AI agents](https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents)|✅|


#### Information Retrieval / RAG

|Format| Resource| Progress |
|---|---|---|
|Course| [Course: Fullstack Retrieval](https://community.fullstackretrieval.com/)|⬜ |
||[Systematically Improving RAG](https://567-labs.github.io/systematically-improving-rag/)|⬜|
|DeepLearning.AI|[Building and Evaluating Advanced RAG Applications](https://www.deeplearning.ai/short-courses/building-evaluating-advanced-rag/)|✅|
||[Vector Databases: from Embeddings to Applications](https://www.deeplearning.ai/short-courses/vector-databases-embeddings-applications/)|✅|
||[Advanced Retrieval for AI with Chroma](https://www.deeplearning.ai/short-courses/advanced-retrieval-for-ai/)|✅|
||[Prompt Compression and Query Optimization](https://www.deeplearning.ai/short-courses/prompt-compression-and-query-optimization/)|✅|
||[Large Language Models with Semantic Search](https://www.deeplearning.ai/short-courses/large-language-models-semantic-search) `1hr`|✅|
||[Building Applications with Vector Databases](https://www.deeplearning.ai/short-courses/building-applications-vector-databases/)|✅|
||[Knowledge Graphs for RAG](https://www.deeplearning.ai/short-courses/knowledge-graphs-rag/)|⬜|
||[Preprocessing Unstructured Data for LLM Applications](https://www.deeplearning.ai/short-courses/preprocessing-unstructured-data-for-llm-applications/)|⬜|
||[Embedding Models: From Architecture to Implementation](https://www.deeplearning.ai/short-courses/embedding-models-from-architecture-to-implementation)|✅|
||[Retrieval Optimization - From Tokenization to Vector Quantization](https://www.deeplearning.ai/short-courses/retrieval-optimization-from-tokenization-to-vector-quantization/)|✅|
|Youtube|[Systematically improving RAG applications](https://youtu.be/RrDBV6odPKo?list=PLgIaq8VgndJvXkDSeReTl2u4rQMShkZ6V)|✅|
||[Back to Basics for RAG w/ Jo Bergum](https://www.youtube.com/watch?v=nc0BupOkrhI&list=PLgIaq8VgndJvXkDSeReTl2u4rQMShkZ6V&index=2)|✅|
||[Beyond the Basics of Retrieval for Augmenting Generation (w/ Ben Clavié)](https://www.youtube.com/watch?v=0nA5QG3087g&t=1287s)|✅|
||[RAG From Scratch](https://www.youtube.com/playlist?list=PLfaIDFEXuae2LXbO1_PKyVJiQ23ZztA0x) `14/14`|✅|
||[CMU Advanced NLP Fall 2024 (10): Retrieval and RAG](https://www.youtube.com/watch?v=KfQaYk4k9eM&list=PL8PYTP1V4I8D4BeyjwWczukWq9d8PNyZp&index=6) `1h17m`|✅|
||[What You See Is What You Search: Vision Language Models for PDF Retrieval [Jo Bergum]](https://youtu.be/qrbQUU4TrLM)|✅|
|Article| [Pretrained Transformer Language Models for Search - part 1](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-1/#) | ✅        |
|| [Pretrained Transformer Language Models for Search - part 2](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-2/)  | ✅        |
|| [Pretrained Transformer Language Models for Search - part 3](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-3)   | ✅       |
|| [Pretrained Transformer Language Models for Search - part 4](https://blog.vespa.ai/pretrained-transformer-language-models-for-search-part-4)   | ✅        |
||[How not to use BERT for Document Ranking](https://bergum.medium.com/how-not-to-use-bert-for-search-ranking-4586716428d9)|✅|
|| [Understanding LanceDB's IVF-PQ index](https://lancedb.github.io/lancedb/concepts/index_ivfpq/)                                                | ✅        |
|| [A little pooling goes a long way for multi-vector representations](https://www.answer.ai/posts/colbert-pooling.html)                          | ✅        |
||[Levels of Complexity: RAG Applications](https://jxnl.github.io/blog/writing/2024/02/28/levels-of-complexity-rag-applications/)|✅|
||[Systematically Improving Your RAG](https://jxnl.github.io/blog/writing/2024/05/22/systematically-improving-your-rag/)|✅|
||[Stop using LGTM@Few as a metric (Better RAG)](https://jxnl.github.io/blog/writing/2024/02/05/when-to-lgtm-at-k/)|✅|
||[Low-Hanging Fruit for RAG Search](https://jxnl.github.io/blog/writing/2024/05/11/low-hanging-fruit-for-rag-search/)|✅|
||[What AI Engineers Should Know about Search](https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search)|✅|
||[Evaluating Chunking Strategies for Retrieval](https://research.trychroma.com/evaluating-chunking)|✅|
||[Sentence Embeddings. Introduction to Sentence Embeddings](https://osanseviero.github.io/hackerllama/blog/posts/sentence_embeddings/)|✅|
||[LambdaMART in Depth](https://softwaredoug.com/blog/2022/01/17/lambdamart-in-depth)|⬜|
||[Guided Generation with Outlines](https://medium.com/canoe-intelligence-technology/guided-generation-with-outlines-c09a0c2ce9eb)|✅|
||[RAG tricks from the trenches](https://duarteocarmo.com/blog/rag-tricks-from-the-trenches)|⬜|
||[Retrieval 101](https://isaacflath.com/blog/blog_post?fpath=posts%2F2025-03-17-Retrieval101.ipynb)|⬜|
||[Understanding the BM25 full text search algorithm](https://emschwartz.me/understanding-the-bm25-full-text-search-algorithm/)|⬜|
||[Arxiv: Ragas: Automated Evaluation of Retrieval Augmented Generation](https://arxiv.org/abs/2309.15217)|✅|
||[Pinecone: Vector Databases in Production for Busy Engineers](https://www.pinecone.io/learn/series/vector-databases-in-production-for-busy-engineers/)|✅|
||[Pinecone: Retrieval Augmented Generation](https://www.pinecone.io/learn/series/rag/)|✅|
||[Pinecone: Faiss: The Missing Manual](https://www.pinecone.io/learn/series/faiss/)|✅|
||[Pinecone: Natural Language Processing for Semantic Search](https://www.pinecone.io/learn/series/nlp/)|0/13|
||[Guidance: Token Healing](https://github.com/guidance-ai/guidance/blob/main/notebooks/tutorials/token_healing.ipynb)|⬜|


#### Agentic Engineering

|Format|Resource|Progress|
|---|---|---|
|DeepLearning.AI|[Agentic AI with Andrew Ng](https://www.deeplearning.ai/courses/agentic-ai/)|✅|
||[Building Agentic RAG with LlamaIndex](https://www.deeplearning.ai/short-courses/building-agentic-rag-with-llamaindex/)|✅|
||[Multi AI Agent Systems with crewAI](https://www.deeplearning.ai/short-courses/multi-ai-agent-systems-with-crewai/)|✅|
||[Building Towards Computer Use with Anthropic](https://www.deeplearning.ai/short-courses/building-towards-computer-use-with-anthropic/)|✅|
||[Pydantic for LLM Workflows](https://www.deeplearning.ai/short-courses/pydantic-for-llm-workflows/)|✅|
||[Practical Multi AI Agents and Advanced Use Cases with crewAI](https://www.deeplearning.ai/short-courses/practical-multi-ai-agents-and-advanced-use-cases-with-crewai/)|⬜|
||[LLMs as Operating Systems: Agent Memory](https://www.deeplearning.ai/short-courses/llms-as-operating-systems-agent-memory/)|✅|
||[Serverless Agentic Workflows with Amazon Bedrock](https://www.deeplearning.ai/short-courses/serverless-agentic-workflows-with-amazon-bedrock/)|⬜|
||[AI Agentic Design Patterns with AutoGen](https://www.deeplearning.ai/short-courses/ai-agentic-design-patterns-with-autogen/)|⬜|
||[AI Agents in LangGraph](https://www.deeplearning.ai/short-courses/ai-agents-in-langgraph/)|⬜|
||[Building Your Own Database Agent](https://www.deeplearning.ai/short-courses/building-your-own-database-agent/)|⬜|
||[Function-Calling and Data Extraction with LLMs](https://www.deeplearning.ai/short-courses/function-calling-and-data-extraction-with-llms/) `59m`|✅|
||[Evaluating AI Agents](https://www.deeplearning.ai/short-courses/evaluating-ai-agents/) `2h16m`|✅|
||[Building AI Browser Agents](https://www.deeplearning.ai/short-courses/building-ai-browser-agents)|⬜|
|Course|[Berkeley: CS294/194-196 Large Language Model Agents](https://www.youtube.com/playlist?list=PLS01nW3RtgopsNLeM936V4TNSsvvVglLc) `0/14 lectures`|⬜|
||[Huggingface: Agents Course](https://huggingface.co/learn/agents-course/unit1/messages-and-special-tokens#base-models-vs-instruct-models)|Unit 1|
||[Berkeley: Advanced LLM Agents MOOC](https://www.youtube.com/playlist?list=PLS01nW3RtgorL3AW8REU9nGkzhvtn6Egn) `0/12 lectures`|⬜|
|Youtube|[OpenAI: Assistants & Agents Build Hour](https://vimeo.com/showcase/11333741/video/990334325)|✅|
||[OpenAI: Function Calling Build Hour](https://vimeo.com/showcase/11333741/video/952127114)|✅|
||[How to Evaluate Agents: Galileo’s Agentic Evaluations in Action](https://www.youtube.com/watch?v=QvStk5G8BZw)|✅|
||[Agent Response \| LangSmith Evaluation - Part 24](https://youtu.be/NbQKDfSw3gM?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S)|✅|
||[Single Step \| LangSmith Evaluation - Part 25](https://youtu.be/AVPflFmRkd4?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S)|✅|
||[Agent Trajectory \| LangSmith Evaluation - Part 26](https://youtu.be/pvlT056DAHs?list=PLfaIDFEXuae0um8Fj0V4dHG37fGFU8Q5S)|✅|
||[Evaluating Agents and Assistants: The AI Conference](https://www.youtube.com/watch?v=6uXWhmDRcMc)|✅|
||[How to Build, Evaluate, and Iterate on LLM Agents](https://youtu.be/0pnEUAwoDP0)|✅|
||[How Claude Code Works - Jared Zoneraich, PromptLayer](https://www.youtube.com/watch?v=RFKCzGlAU6Q)|✅|
|Article|[Tool Invocation - Demonstrating the Marvel of GPT's Flexibility](https://blog.jnbrymn.com/2024/01/30/the-marvel-of-GPT-generality.html)|✅|
||[Introducing smolagents, a simple library to build agents](https://huggingface.co/blog/smolagents)|✅|
||[What Problem Does The Model Context Protocol Solve?](https://www.aihero.dev/what-problem-does-model-context-protocol-solve)|✅|
||[Don’t Build Multi-Agents](https://cognition.ai/blog/dont-build-multi-agents)|✅|
||[Coding Agents 101: The Art of Actually Getting Things Done](https://devin.ai/agents101)|✅|
||[What makes Claude Code so damn good (and how to recreate that magic in your agent)!?](https://minusx.ai/blog/decoding-claude-code/)|✅|
||[Anthropic: Building effective agents](https://www.anthropic.com/research/building-effective-agents)|✅|
||[Anthropic: Building Effective Agents Cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents)|✅|
||[Anthropic: Writing effective tools for agents — with agents](https://www.anthropic.com/engineering/writing-tools-for-agents)|✅|

## Technical Skills (Libraries/Frameworks/Tools)

### CSS

|Format|Resource|Progress|
|---|---|---|
|Pluralsight|[CSS Positioning](https://www.pluralsight.com/courses/css-positioning-1834)|✅|
||[Introduction to CSS](https://www.pluralsight.com/courses/css-intro)|✅|
||[CSS: Specificity, the Box Model, and Best Practices](https://app.pluralsight.com/interactive-courses/detail/c580b092-d94a-4ed8-8d2a-2f4d0b76f99f)|✅|
||[CSS: Using Flexbox for Layout](https://app.pluralsight.com/interactive-courses/detail/a089d0a5-4a4c-4c4e-b883-c1bc64009619)|✅|
||[Code School: Blasting Off with Bootstrap](https://www.pluralsight.com/courses/code-school-blasting-off-with-bootstrap)|✅|
|Codecademy|[Learn SASS](https://www.codecademy.com/learn/learn-sass)|✅|
|Course|[CSS for Javascript Developers](https://css-for-js.dev/)|✅|



### Django

|Format|Resource|Progress|
|---|---|---|
|Article|[Django, HTMX and Alpine.js: Modern websites, JavaScript optional](https://www.saaspegasus.com/guides/modern-javascript-for-django-developers/htmx-alpine/)|✅|

### HTML

|Format|Resource|Progress|
|---|---|---|
|Codecademy|[Learn HTML](https://www.codecademy.com/learn/learn-html)|✅|
||[Make a website](https://www.codecademy.com/en/courses/make-a-website)|✅|
|Article|[Alternative Text](https://webaim.org/techniques/alttext/)|⬜|

### Langchain

|Format|Resource|Progress|
|---|---|---|
|Course|[Pinecone: LangChain AI Handbook](https://www.pinecone.io/learn/series/langchain/)|0/11|
|DeepLearning.AI|[LangChain for LLM Application Development](https://www.deeplearning.ai/short-courses/langchain-for-llm-application-development/)|⬜|
||[LangChain: Chat with Your Data](https://www.deeplearning.ai/short-courses/langchain-chat-with-your-data/)|⬜|


### JavaScript

|Format|Resource|Progress|
|---|---|---|
|Codecademy|[Learn JavaScript](https://www.codecademy.com/learn/learn-javascript)|✅|
||[Jquery Track](https://www.codecademy.com/learn/learn-jquery)|✅|
|Udacity|[ES6 - JavaScript Improved](https://www.udacity.com/course/es6-javascript-improved--ud356)|✅|
||[Intro to Javascript](https://www.udacity.com/course/intro-to-javascript--ud803)|✅|
||[Object Oriented JS 1](https://www.udacity.com/course/object-oriented-javascript--ud015)|✅|
||[Object Oriented JS 2](https://www.udacity.com/course/object-oriented-javascript--ud711)|✅|
|Udemy|[Understanding Typescript](https://www.udemy.com/understanding-typescript/)|✅|


### Matplotlib

|Format|Resource|Progress|
|---|---|---|
|Datacamp|[Introduction to Seaborn](https://www.datacamp.com/courses/introduction-to-seaborn)|✅|
||[Introduction to Matplotlib](https://www.datacamp.com/courses/introduction-to-matplotlib)|✅|


### MLFlow

|Format|Resource|Progress|
|---|---|---|
|Datacamp|[Introduction to MLFlow](https://www.datacamp.com/courses/introduction-to-mlflow)|✅|


### Numpy

|Format|Resource|Progress|
|---|---|---|
|Youtube|[Numpy Array Broadcasting In Python Explained](https://youtu.be/oG1t3qlzq14)|✅|


### Nexxt.JS

|Format|Resource|Progress|
|---|---|---|
|Docs|[Start building with Next.js](https://nextjs.org/learn) |          |

### Pandas

|Format|Resource|Progress|
|---|---|---|
|Datacamp|[Pandas Foundations](https://www.datacamp.com/courses/pandas-foundations)|✅|
||[Pandas Joins for Spreadsheet Users](https://www.datacamp.com/courses/pandas-joins-for-spreadsheet-users)|✅|
||[Manipulating DataFrames with pandas](https://www.datacamp.com/courses/manipulating-dataframes-with-pandas)|✅|
||[Merging DataFrames with pandas](https://www.datacamp.com/courses/merging-dataframes-with-pandas)|✅|
||[Data Manipulation with pandas](https://www.datacamp.com/courses/data-manipulation-with-pandas)|✅|
||[Optimizing Python Code with pandas](https://www.datacamp.com/courses/optimizing-python-code-with-pandas)|✅|
||[Streamlined Data Ingestion with pandas](https://www.datacamp.com/courses/streamlined-data-ingestion-with-pandas)|✅|
||[Analyzing Marketing Campaigns with pandas](https://www.datacamp.com/courses/analyzing-marketing-campaigns-with-pandas)|✅|
||[Analyzing Police Activity with pandas](https://www.datacamp.com/courses/analyzing-police-activity-with-pandas)|✅|


### PyTorch

|Format|Resource|Progress|
|---|---|---|
|Course|[Deeplizard: Neural Network Programming - Deep Learning with PyTorch](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrfNyHZsM6ufI0iZENK9xgG)|✅|
|Datacamp|[Introduction to Deep Learning with PyTorch](https://www.datacamp.com/courses/deep-learning-with-pytorch)|✅|
||[Intermediate Deep Learning with PyTorch](https://app.datacamp.com/learn/courses/intermediate-deep-learning-with-pytorch)|⬜|
||[Deep Learning for Text with PyTorch](https://www.datacamp.com/courses/deep-learning-for-text-with-pytorch)|⬜|
||[Deep Learning for Images with PyTorch](https://www.datacamp.com/courses/deep-learning-for-images-with-pytorch)|⬜|
|Article|[PyTorch internals](https://blog.ezyang.com/2019/05/pytorch-internals/)|⬜|
||[Taking PyTorch For Granted](https://nrehiew.github.io/blog/pytorch/)|⬜|


### ReactJS

|Format|Resource|Progress|
|---|---|---|
|Codecademy|[Learn ReactJS: Part I](https://www.codecademy.com/learn/react-101)|✅|
||[Learn ReactJS: Part II](https://www.codecademy.com/learn/react-102)|✅|
|Course|[NexxtJS: React Foundations](https://nextjs.org/learn/react-foundations)|⬜|

### Spacy

|Format|Resource|Progress|
|---|---|---|
|Datacamp|[Advanced NLP with spaCy](https://www.datacamp.com/courses/advanced-nlp-with-spacy)|✅|

### Tensorflow & Keras

|Format|Resource|Progress|
|---|---|---|
|Course|[Deeplizard: Keras - Python Deep Learning Neural Network API](https://www.youtube.com/playlist?list=PLZbbT5o_s2xrwRnXk_yCPtnqqo4_u2YGL)|✅|
|Datacamp|[Introduction to TensorFlow in Python](https://www.datacamp.com/courses/introduction-to-tensorflow-in-python)|✅|
||[Deep Learning in Python](https://www.datacamp.com/courses/deep-learning-in-python)|✅|
||[Introduction to Deep Learning with Keras](https://www.datacamp.com/courses/deep-learning-with-keras-in-python)|✅|
||[Advanced Deep Learning with Keras](https://www.datacamp.com/courses/advanced-deep-learning-with-keras-in-python)|✅|
|Udacity|[Intro to TensorFlow for Deep Learning](https://www.udacity.com/course/intro-to-tensorflow-for-deep-learning--ud187)|✅|


## Miscellaneous


### Marketing

|Format|Resource|Progress|
|---|---|---|
|Course|[Build Once, Sell Twice](https://visualizevalue.com/products/build-once-sell-twice-the-productization-playbook)|✅|

### Search Engine Optimization (SEO)

|Format|Resource|Progress|
|---|---|---|
|Course|[Compound Content](https://visualizevalue.com/products/compound-content)|✅|

### Technical Writing
|Format|Resource|Progress|
|---|---|---|
|Book|[The Tech Resume Inside Out](https://thetechresume.com)|✅|
|Course|[Google: Technical Writing Course](https://developers.google.com/tech-writing/overview)|⬜|
||[Writing Better](https://www.julian.com/guide/write/intro)|⬜|